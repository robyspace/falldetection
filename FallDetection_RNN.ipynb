{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":90641,"status":"ok","timestamp":1709794219065,"user":{"displayName":"Vistronics India","userId":"16074982155385528679"},"user_tz":-330},"id":"2SkvX1TtEAxn","outputId":"8f1ad123-0094-4388-cbc8-aa1cace86061"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2053,"status":"ok","timestamp":1709794243919,"user":{"displayName":"Vistronics India","userId":"16074982155385528679"},"user_tz":-330},"id":"mKHL3VCBGUMu","outputId":"3c10865a-4df0-4f63-cfdc-779e3b101a26"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Projects_2023/SHALINI/Sources/SisFall_RNN\n","1DCNN.py  ADL  FALL  MLP  Processed  README.md\tRNN  SisFall_dataset  Testing.py\n"]}],"source":["%cd /content/drive/MyDrive/Projects_2023/SHALINI/Sources/SisFall_RNN/\n","!ls"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1709794247338,"user":{"displayName":"Vistronics India","userId":"16074982155385528679"},"user_tz":-330},"id":"5tw5JYB8HX16","outputId":"9b02aa1d-626c-4a8c-fc59-7fa638b891ac"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Projects_2023/SHALINI/Sources/SisFall_RNN/RNN\n"]}],"source":["%cd RNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ADOTdw4NHe7a"},"outputs":[],"source":["!python LoadDataRNN.py\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ntk7yWrEY6n1","executionInfo":{"status":"ok","timestamp":1703068382524,"user_tz":-330,"elapsed":1264377,"user":{"displayName":"Vistronics India","userId":"16074982155385528679"}},"outputId":"d7850a1d-421f-444b-a3f5-f5f01bedc398"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Projects_2023/SHALINI/Sources/SisFall_RNN/RNN\n","2023-12-20 10:11:58.592133: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-20 10:11:58.592188: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-20 10:11:58.593601: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-20 10:11:58.601212: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-12-20 10:11:59.683841: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Before Filtering: Shape of X1: (4500, 1500, 1) Shape of Y1: (4500, 1500, 2)\n","After Filtering: Shape of X2: (4500, 1500, 1) Shape of Y2: (4500, 1500, 2)\n","Before Filtering: Shape of X1_train: (3150, 1500, 1) Shape of Y1_train: (3150, 1500, 2)\n","After Filtering: Shape of X2_train: (3150, 1500, 1) Shape of Y2_train: (3150, 1500, 2)\n","2023-12-20 10:12:01.922741: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-20 10:12:01.973269: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-20 10:12:01.973558: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-20 10:12:01.974836: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-20 10:12:01.975059: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-20 10:12:01.975237: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-20 10:12:02.070877: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-20 10:12:02.071140: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-20 10:12:02.071281: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-12-20 10:12:02.071356: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-20 10:12:02.071497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13949 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, 1500, 128)         66560     \n","                                                                 \n"," batch_normalization (Batch  (None, 1500, 128)         512       \n"," Normalization)                                                  \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1500, 64)          49408     \n","                                                                 \n"," batch_normalization_1 (Bat  (None, 1500, 64)          256       \n"," chNormalization)                                                \n","                                                                 \n"," lstm_2 (LSTM)               (None, 1500, 32)          12416     \n","                                                                 \n"," batch_normalization_2 (Bat  (None, 1500, 32)          128       \n"," chNormalization)                                                \n","                                                                 \n"," dense (Dense)               (None, 1500, 16)          528       \n","                                                                 \n"," dropout (Dropout)           (None, 1500, 16)          0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1500, 2)           34        \n","                                                                 \n","=================================================================\n","Total params: 129842 (507.20 KB)\n","Trainable params: 129394 (505.45 KB)\n","Non-trainable params: 448 (1.75 KB)\n","_________________________________________________________________\n","Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_3 (LSTM)               (None, 1500, 128)         66560     \n","                                                                 \n"," batch_normalization_3 (Bat  (None, 1500, 128)         512       \n"," chNormalization)                                                \n","                                                                 \n"," lstm_4 (LSTM)               (None, 1500, 64)          49408     \n","                                                                 \n"," batch_normalization_4 (Bat  (None, 1500, 64)          256       \n"," chNormalization)                                                \n","                                                                 \n"," lstm_5 (LSTM)               (None, 1500, 32)          12416     \n","                                                                 \n"," batch_normalization_5 (Bat  (None, 1500, 32)          128       \n"," chNormalization)                                                \n","                                                                 \n"," dense_2 (Dense)             (None, 1500, 16)          528       \n","                                                                 \n"," dropout_1 (Dropout)         (None, 1500, 16)          0         \n","                                                                 \n"," dense_3 (Dense)             (None, 1500, 2)           34        \n","                                                                 \n","=================================================================\n","Total params: 129842 (507.20 KB)\n","Trainable params: 129394 (505.45 KB)\n","Non-trainable params: 448 (1.75 KB)\n","_________________________________________________________________\n","Training model w/ data after filtering...\n","Epoch 1/100\n","2023-12-20 10:12:08.984086: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8906\n","2023-12-20 10:12:10.753890: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f576108fd90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2023-12-20 10:12:10.753931: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2023-12-20 10:12:10.759912: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1703067130.871781   70961 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","79/79 [==============================] - 20s 158ms/step - loss: 0.6942 - accuracy: 0.5725 - val_loss: 0.6760 - val_accuracy: 0.6000\n","Epoch 2/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.6661 - accuracy: 0.6176 - val_loss: 0.6731 - val_accuracy: 0.6000\n","Epoch 3/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.6351 - accuracy: 0.6540 - val_loss: 0.6777 - val_accuracy: 0.6000\n","Epoch 4/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.6005 - accuracy: 0.6765 - val_loss: 0.6895 - val_accuracy: 0.6000\n","Epoch 5/100\n","79/79 [==============================] - 11s 145ms/step - loss: 0.5806 - accuracy: 0.6890 - val_loss: 0.7081 - val_accuracy: 0.6008\n","Epoch 6/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5783 - accuracy: 0.6898 - val_loss: 0.6898 - val_accuracy: 0.5649\n","Epoch 7/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5764 - accuracy: 0.6811 - val_loss: 0.7524 - val_accuracy: 0.5994\n","Epoch 8/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5645 - accuracy: 0.6955 - val_loss: 0.6545 - val_accuracy: 0.5769\n","Epoch 9/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5550 - accuracy: 0.7010 - val_loss: 0.6136 - val_accuracy: 0.6152\n","Epoch 10/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5432 - accuracy: 0.7114 - val_loss: 0.8521 - val_accuracy: 0.4588\n","Epoch 11/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5398 - accuracy: 0.7152 - val_loss: 0.6615 - val_accuracy: 0.5994\n","Epoch 12/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5308 - accuracy: 0.7236 - val_loss: 0.5937 - val_accuracy: 0.6751\n","Epoch 13/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5214 - accuracy: 0.7320 - val_loss: 0.6361 - val_accuracy: 0.5944\n","Epoch 14/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5165 - accuracy: 0.7342 - val_loss: 0.5797 - val_accuracy: 0.6844\n","Epoch 15/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5095 - accuracy: 0.7392 - val_loss: 0.5084 - val_accuracy: 0.7385\n","Epoch 16/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.5053 - accuracy: 0.7420 - val_loss: 0.6375 - val_accuracy: 0.6067\n","Epoch 17/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5065 - accuracy: 0.7432 - val_loss: 0.6040 - val_accuracy: 0.6659\n","Epoch 18/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5004 - accuracy: 0.7475 - val_loss: 0.6327 - val_accuracy: 0.6126\n","Epoch 19/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.4981 - accuracy: 0.7486 - val_loss: 0.5254 - val_accuracy: 0.7185\n","Epoch 20/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4921 - accuracy: 0.7523 - val_loss: 0.6456 - val_accuracy: 0.5707\n","Epoch 21/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4901 - accuracy: 0.7538 - val_loss: 0.6279 - val_accuracy: 0.5937\n","Epoch 22/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.4877 - accuracy: 0.7564 - val_loss: 0.5053 - val_accuracy: 0.7452\n","Epoch 23/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4899 - accuracy: 0.7550 - val_loss: 0.5284 - val_accuracy: 0.7291\n","Epoch 24/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.4842 - accuracy: 0.7572 - val_loss: 0.6244 - val_accuracy: 0.6042\n","Epoch 25/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4836 - accuracy: 0.7568 - val_loss: 0.6461 - val_accuracy: 0.6122\n","Epoch 26/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4810 - accuracy: 0.7629 - val_loss: 0.4585 - val_accuracy: 0.7755\n","Epoch 27/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.4762 - accuracy: 0.7650 - val_loss: 0.4666 - val_accuracy: 0.7678\n","Epoch 28/100\n","79/79 [==============================] - 11s 145ms/step - loss: 0.4697 - accuracy: 0.7684 - val_loss: 0.4701 - val_accuracy: 0.7699\n","Epoch 29/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4695 - accuracy: 0.7689 - val_loss: 0.4936 - val_accuracy: 0.7575\n","Epoch 30/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.4706 - accuracy: 0.7681 - val_loss: 0.6172 - val_accuracy: 0.6575\n","Epoch 31/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4632 - accuracy: 0.7716 - val_loss: 0.6686 - val_accuracy: 0.6301\n","Epoch 32/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.4621 - accuracy: 0.7742 - val_loss: 0.4754 - val_accuracy: 0.7648\n","Epoch 33/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.4604 - accuracy: 0.7769 - val_loss: 0.6947 - val_accuracy: 0.6241\n","Epoch 34/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4592 - accuracy: 0.7745 - val_loss: 0.6473 - val_accuracy: 0.6630\n","Epoch 35/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.4668 - accuracy: 0.7730 - val_loss: 0.5628 - val_accuracy: 0.7180\n","Epoch 36/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4574 - accuracy: 0.7751 - val_loss: 0.5225 - val_accuracy: 0.7429\n","Epoch 37/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.4585 - accuracy: 0.7743 - val_loss: 0.7222 - val_accuracy: 0.6017\n","Epoch 38/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.4767 - accuracy: 0.7658 - val_loss: 0.6062 - val_accuracy: 0.6657\n","Epoch 39/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4568 - accuracy: 0.7770 - val_loss: 0.6076 - val_accuracy: 0.7246\n","Epoch 40/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4391 - accuracy: 0.7871 - val_loss: 0.4736 - val_accuracy: 0.7785\n","Epoch 41/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4409 - accuracy: 0.7875 - val_loss: 0.7019 - val_accuracy: 0.6330\n","Epoch 42/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4456 - accuracy: 0.7868 - val_loss: 0.6652 - val_accuracy: 0.6397\n","Epoch 43/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.4425 - accuracy: 0.7870 - val_loss: 0.7103 - val_accuracy: 0.6075\n","Epoch 44/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4240 - accuracy: 0.7988 - val_loss: 0.6809 - val_accuracy: 0.6589\n","Epoch 45/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4241 - accuracy: 0.8007 - val_loss: 0.4713 - val_accuracy: 0.7684\n","Epoch 46/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4592 - accuracy: 0.7809 - val_loss: 0.4993 - val_accuracy: 0.7586\n","Epoch 47/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4454 - accuracy: 0.7876 - val_loss: 0.4360 - val_accuracy: 0.7989\n","Epoch 48/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4230 - accuracy: 0.8022 - val_loss: 0.4976 - val_accuracy: 0.7762\n","Epoch 49/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4236 - accuracy: 0.8022 - val_loss: 0.5725 - val_accuracy: 0.7279\n","Epoch 50/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.4365 - accuracy: 0.7942 - val_loss: 1.0512 - val_accuracy: 0.6784\n","Epoch 51/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.4189 - accuracy: 0.8041 - val_loss: 0.5038 - val_accuracy: 0.7522\n","Epoch 52/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4140 - accuracy: 0.8055 - val_loss: 0.4217 - val_accuracy: 0.8040\n","Epoch 53/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4161 - accuracy: 0.8047 - val_loss: 0.5893 - val_accuracy: 0.6666\n","Epoch 54/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4041 - accuracy: 0.8105 - val_loss: 0.8281 - val_accuracy: 0.5618\n","Epoch 55/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4248 - accuracy: 0.7972 - val_loss: 0.4152 - val_accuracy: 0.8047\n","Epoch 56/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.3975 - accuracy: 0.8158 - val_loss: 0.4790 - val_accuracy: 0.7846\n","Epoch 57/100\n","79/79 [==============================] - 11s 145ms/step - loss: 0.3979 - accuracy: 0.8152 - val_loss: 0.4261 - val_accuracy: 0.8055\n","Epoch 58/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.3907 - accuracy: 0.8180 - val_loss: 0.4233 - val_accuracy: 0.8026\n","Epoch 59/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.3941 - accuracy: 0.8166 - val_loss: 0.8373 - val_accuracy: 0.5771\n","Epoch 60/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4193 - accuracy: 0.8032 - val_loss: 0.4413 - val_accuracy: 0.7864\n","Epoch 61/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.4295 - accuracy: 0.7986 - val_loss: 0.4869 - val_accuracy: 0.7641\n","Epoch 62/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.3989 - accuracy: 0.8161 - val_loss: 0.4145 - val_accuracy: 0.8125\n","Epoch 63/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.3958 - accuracy: 0.8203 - val_loss: 0.3976 - val_accuracy: 0.8143\n","Epoch 64/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.3924 - accuracy: 0.8201 - val_loss: 0.4260 - val_accuracy: 0.8063\n","Epoch 65/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.3854 - accuracy: 0.8240 - val_loss: 0.3928 - val_accuracy: 0.8185\n","Epoch 66/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.3837 - accuracy: 0.8231 - val_loss: 0.5522 - val_accuracy: 0.7393\n","Epoch 67/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.3811 - accuracy: 0.8236 - val_loss: 0.5232 - val_accuracy: 0.7467\n","Epoch 68/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.3939 - accuracy: 0.8174 - val_loss: 0.7079 - val_accuracy: 0.6286\n","Epoch 69/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4131 - accuracy: 0.8021 - val_loss: 0.4383 - val_accuracy: 0.7944\n","Epoch 70/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.3903 - accuracy: 0.8184 - val_loss: 0.4270 - val_accuracy: 0.8058\n","Epoch 71/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.3834 - accuracy: 0.8228 - val_loss: 0.4002 - val_accuracy: 0.8188\n","Epoch 72/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.3769 - accuracy: 0.8275 - val_loss: 0.4357 - val_accuracy: 0.7969\n","Epoch 73/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.3797 - accuracy: 0.8248 - val_loss: 0.7702 - val_accuracy: 0.6241\n","Epoch 74/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.3821 - accuracy: 0.8241 - val_loss: 0.4434 - val_accuracy: 0.7910\n","Epoch 75/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.3743 - accuracy: 0.8281 - val_loss: 0.3874 - val_accuracy: 0.8156\n","Epoch 76/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.3800 - accuracy: 0.8277 - val_loss: 0.5386 - val_accuracy: 0.7785\n","Epoch 77/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4222 - accuracy: 0.8047 - val_loss: 0.5170 - val_accuracy: 0.7578\n","Epoch 78/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.4278 - accuracy: 0.8046 - val_loss: 0.4510 - val_accuracy: 0.7898\n","Epoch 79/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.4575 - accuracy: 0.7785 - val_loss: 0.7094 - val_accuracy: 0.6705\n","Epoch 80/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.4569 - accuracy: 0.7883 - val_loss: 0.4902 - val_accuracy: 0.7897\n","Training model w/ data before filtering...\n","Epoch 1/100\n","79/79 [==============================] - 18s 158ms/step - loss: 0.7030 - accuracy: 0.5550 - val_loss: 0.6752 - val_accuracy: 0.6000\n","Epoch 2/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.6765 - accuracy: 0.5959 - val_loss: 0.6748 - val_accuracy: 0.6000\n","Epoch 3/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.6522 - accuracy: 0.6315 - val_loss: 0.6751 - val_accuracy: 0.6000\n","Epoch 4/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.6019 - accuracy: 0.6705 - val_loss: 0.6763 - val_accuracy: 0.6002\n","Epoch 5/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5896 - accuracy: 0.6789 - val_loss: 0.6804 - val_accuracy: 0.6002\n","Epoch 6/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5853 - accuracy: 0.6820 - val_loss: 0.6795 - val_accuracy: 0.6014\n","Epoch 7/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.5830 - accuracy: 0.6851 - val_loss: 0.7101 - val_accuracy: 0.5112\n","Epoch 8/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5813 - accuracy: 0.6870 - val_loss: 0.7054 - val_accuracy: 0.5468\n","Epoch 9/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5759 - accuracy: 0.6918 - val_loss: 0.6067 - val_accuracy: 0.5948\n","Epoch 10/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5698 - accuracy: 0.6998 - val_loss: 0.6129 - val_accuracy: 0.5860\n","Epoch 11/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.5638 - accuracy: 0.7077 - val_loss: 0.5859 - val_accuracy: 0.6892\n","Epoch 12/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5593 - accuracy: 0.7119 - val_loss: 0.5820 - val_accuracy: 0.6838\n","Epoch 13/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5584 - accuracy: 0.7125 - val_loss: 0.5864 - val_accuracy: 0.6933\n","Epoch 14/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5531 - accuracy: 0.7161 - val_loss: 0.5632 - val_accuracy: 0.7071\n","Epoch 15/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5544 - accuracy: 0.7146 - val_loss: 0.8805 - val_accuracy: 0.6204\n","Epoch 16/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5508 - accuracy: 0.7182 - val_loss: 0.5861 - val_accuracy: 0.6839\n","Epoch 17/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5520 - accuracy: 0.7155 - val_loss: 1.0135 - val_accuracy: 0.5885\n","Epoch 18/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.5510 - accuracy: 0.7154 - val_loss: 0.9052 - val_accuracy: 0.6489\n","Epoch 19/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.5448 - accuracy: 0.7237 - val_loss: 0.6853 - val_accuracy: 0.6286\n","Epoch 20/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5433 - accuracy: 0.7233 - val_loss: 0.6031 - val_accuracy: 0.6544\n","Epoch 21/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.5408 - accuracy: 0.7236 - val_loss: 0.8222 - val_accuracy: 0.6580\n","Epoch 22/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5354 - accuracy: 0.7232 - val_loss: 0.8058 - val_accuracy: 0.6603\n","Epoch 23/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.5317 - accuracy: 0.7224 - val_loss: 0.9481 - val_accuracy: 0.4582\n","Epoch 24/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5247 - accuracy: 0.7270 - val_loss: 0.9305 - val_accuracy: 0.6370\n","Epoch 25/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5228 - accuracy: 0.7267 - val_loss: 0.7170 - val_accuracy: 0.6113\n","Epoch 26/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5219 - accuracy: 0.7259 - val_loss: 1.0116 - val_accuracy: 0.6043\n","Epoch 27/100\n","79/79 [==============================] - 11s 143ms/step - loss: 0.5195 - accuracy: 0.7279 - val_loss: 0.6440 - val_accuracy: 0.6365\n","Epoch 28/100\n","79/79 [==============================] - 11s 145ms/step - loss: 0.5156 - accuracy: 0.7299 - val_loss: 0.9362 - val_accuracy: 0.6545\n","Epoch 29/100\n","79/79 [==============================] - 11s 144ms/step - loss: 0.5142 - accuracy: 0.7309 - val_loss: 0.9735 - val_accuracy: 0.6278\n","Evaluating models...\n","43/43 [==============================] - 2s 48ms/step - loss: 0.9735 - accuracy: 0.6278\n","43/43 [==============================] - 2s 50ms/step - loss: 0.4902 - accuracy: 0.7897\n","Evaluated Accuracy\n","------------------\n","Before Filter: 62.7800%\n","After Filter: 78.9725%\n","Saving history of model without filtering...\n","Saving history of model with filtering...\n"]}],"source":["%cd /content/drive/MyDrive/Projects_2023/SHALINI/Sources/SisFall_RNN/RNN\n","!python RNN.py\n"]},{"cell_type":"code","source":["!python data_plot.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"voY4dNlwYNfJ","executionInfo":{"status":"ok","timestamp":1703078630864,"user_tz":-330,"elapsed":7772,"user":{"displayName":"Vistronics India","userId":"16074982155385528679"}},"outputId":"9aca6787-242f-49cf-d996-78a095e9c7f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-12-20 13:23:44.132257: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-20 13:23:44.132319: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-20 13:23:44.133739: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-20 13:23:44.141273: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-12-20 13:23:45.269410: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Loading RNN's model's history before and after filtering...\n","Plotting graphs for RNN model...\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4249,"status":"ok","timestamp":1703079184195,"user":{"displayName":"Vistronics India","userId":"16074982155385528679"},"user_tz":-330},"id":"QVrzVGkf0STZ","outputId":"1aa1ce92-7b91-43de-a198-da57c792e18d"},"outputs":[{"output_type":"stream","name":"stdout","text":["[NbConvertApp] Converting notebook FallDetection_RNN.ipynb to html\n","[NbConvertApp] Writing 607908 bytes to FallDetection_RNN.html\n"]}],"source":["!jupyter nbconvert FallDetection_RNN.ipynb --to html"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"/v2/external/notebooks/pro.ipynb","timestamp":1698343899387}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}